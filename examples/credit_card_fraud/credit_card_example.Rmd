---
title: 'Credit Card Fraud Detection Example'
output:
  html_document:
    fig_height: 6
    fig_width: 9
    highlight: tango
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 2
  html_notebook:
    fig_height: 8
    fig_width: 10
    highlight: tango
    theme: spacelab
    toc_depth: 2
---

# Introduction

Source: https://www.kaggle.com/mlg-ulb/creditcardfraud

The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.


# H2O in R 

```{r}
# Start H2O Local Cluster
library(h2o)
h2o.init(nthreads = -1, max_mem_size = "8g")
h2o.no_progress() # disable the progress bar in HTML output
```


# Data

```{r}
# import credit card data
h_creditcard = h2o.importFile("/Users/jofaichow/Documents/repo_h2o/h2o_training_2018_02/examples/credit_card_fraud/creditcard.csv")
```


```{r}
# Convert "Class" into factor
h_creditcard$Class = as.factor(h_creditcard$Class)
h2o.table(h_creditcard$Class)
```

```{r}
# Quick look
head(h_creditcard)
summary(h_creditcard)
```

```{r}
# Split data into training / validation / holdout
h_split = h2o.splitFrame(h_creditcard, ratios = c(0.8, 0.1), seed = 1234)
h_train = h_split[[1]] 
h_valid = h_split[[2]] 
h_holdout = h_split[[3]] 
```

```{r}
# Quick look
h2o.table(h_train$Class) 
h2o.table(h_valid$Class) 
h2o.table(h_holdout$Class) 
```


# Supervised Learning: Build a Baseline (Random Forest) Model 

```{r}
# Define features
features = setdiff(colnames(h_creditcard), "Class")
print(features)
```

```{r}
# Baseline Random Forest model
model_baseline = h2o.randomForest(x = features,
                                     y = "Class",
                                     training_frame = h_train,
                                     validation_frame = h_valid,
                                     model_id = "baseline",
                                     seed = 1234)
print(model_baseline)
```

```{r}
# Check performance on holdout
h2o.performance(model_baseline, newdata = h_holdout)
```

```{r}
# Variable Importance
h2o.varimp(model_baseline)
```

```{r}
# Variable Importance Plot
h2o.varimp_plot(model_baseline)
```



# Unsupervised Learning: Reconstruction with Autoencoder

```{r}
model_autoenc = h2o.deeplearning(x = features,
                                 training_frame = h_train,
                                 validation_frame = h_valid,
                                 model_id = "autoencoder",
                                 autoencoder = TRUE,
                                 hidden = c(15),
                                 epochs = 10,
                                 activation = "Tanh",
                                 reproducible = TRUE,
                                 seed = 1234)
print(model_autoenc)
```


```{r}
# Calculate reconstruction errors (MSE) on training dataset
recon_err_train = h2o.anomaly(model_autoenc, h_train, per_feature = FALSE)
head(recon_err_train)
```


```{r}
# Visualise reconstruction errors
d_errors = as.data.frame(recon_err_train)
d_errors = d_errors[order(d_errors),]
plot(d_errors)
```




```{r}
d_recon_error_train = data.frame(Class = as.data.frame(h_train$Class),
                                 as.data.frame(recon_err_train)) 
head(d_recon_error_train)
plot(d_recon_error_train)
plot(d_recon_error_train, ylim = c(0, 0.01))
```


# 5: Use a For loop to determine best threshold value


```{r}
# Simple For loop to try different threshold

# min
a = quantile(d_recon_error_train[d_recon_error_train$Class == 0,]$Reconstruction.MSE,
             probs = 0.75)
# max
b = quantile(d_recon_error_train[d_recon_error_train$Class == 1,]$Reconstruction.MSE,
             probs = 0.25)

# define prob
for (n_prob in c(0, 0.25, 0.5, 0.75, 1)) {

  # define threshold
  threshold = ((b - a) * n_prob) + a
  cat("\n\nProbs cutoff:", n_prob, "... Threshold:", threshold, "\n")

  # Split data
  row_train_exp = which(d_recon_error_train$Reconstruction.MSE < threshold)
  row_train_ano = which(d_recon_error_train$Reconstruction.MSE >= threshold)

  # Split training data
  h_train_exp = h_train[row_train_exp,]
  h_train_ano = h_train[row_train_ano,]

  # Train same baseline random forest model with group "Expected"
  model_exp = h2o.randomForest(x = features,
                               y = "Class",
                               training_frame = h_train_exp,
                               validation_frame = h_valid,
                               model_id = "expected",
                               seed = 1234)

  # Train same baseline random forest model with group "Anomalies"
  model_ano = h2o.randomForest(x = features,
                               y = "Class",
                               training_frame = h_train_ano,
                               validation_frame = h_valid,
                               model_id = "anomalies",
                               seed = 1234)

  # Bag the two models for holdout
  yhat_holdout_exp = h2o.predict(model_exp, h_holdout)
  yhat_holdout_ano = h2o.predict(model_ano, h_holdout)
  yhat_holdout_bag = data.frame(exp = as.data.frame(yhat_holdout_exp$p1),
                                ano = as.data.frame(yhat_holdout_ano$p1))
  yhat_holdout_bag$avg = rowMeans(yhat_holdout_bag)

  # Evaluate performance
  library(Metrics)
  d_eval_holdout = data.frame(as.data.frame(h_holdout$Class),
                              predicted = yhat_holdout_bag$avg)
  auc_holdout = Metrics::auc(d_eval_holdout$Class, d_eval_holdout$predicted)

  cat("AUC Holdout (Baseline):", h2o.auc(h2o.performance(model_baseline, h_holdout)), "\n")
  cat("AUC Holdout (Bagging):", auc_holdout, "\n")
  
  cat("Simple Bagging:\n")
  colnames(yhat_holdout_bag) = c("RF_expected", "RF_anomalies", "Simple_Bag")
  print(head(yhat_holdout_bag, 5))
  

}
```

